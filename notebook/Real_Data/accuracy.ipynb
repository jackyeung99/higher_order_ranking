{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import subprocess\n",
    "import shlex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from src.utils.file_handlers import group_dataset_files, read_dataset_files\n",
    "from src.utils.operation_helpers import run_models, split_games\n",
    "from src.utils.c_operation_helpers import  run_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  log-likelihoods  leadership-log-likelihood\n",
      "0          BIN        -1.114381                  -0.797482\n",
      "1         BINL        -1.157404                  -0.847886\n",
      "2        HO_BT        -1.125124                  -0.796702\n",
      "3       HOL_BT        -1.165548                  -0.844139\n",
      "4  Spring_Rank        -1.106598                  -0.808997\n",
      "5    Page_Rank        -1.320841                  -0.897634\n",
      "6   Point_Wise        -1.385558                  -1.065916\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "data, pi_values = read_dataset_files(grouped['00103'], data_dir, is_synthetic=False)\n",
    "\n",
    "# train, test = train_test_split(data, train_size=.8)\n",
    "train, test = split_games(data, .8)\n",
    "\n",
    "df = run_models(train, test, pi_values)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model  av_error    spearman     kendall     prior   HO_Like   HOL_Like  \\\n",
      "0    HO  0.354359   -0.142886   -0.108434   -1.5472  -2.74475  -0.832101   \n",
      "1   HOL  0.323742  -0.0421654  -0.0302674  -1.48279   -2.7423  -0.823259   \n",
      "2   BIN    0.3669   -0.140197   -0.108434  -1.58531  -2.79209  -0.843856   \n",
      "3  BINL  0.342522  -0.0493774  -0.0408463  -1.54139  -2.78931  -0.837696   \n",
      "\n",
      "  iterations  \n",
      "0         10  \n",
      "1          9  \n",
      "2         10  \n",
      "3         10  \n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "edge_file = grouped['00103']['edges']\n",
    "node_file = grouped['00103']['nodes']\n",
    "\n",
    "edge_path = os.path.join(data_dir, edge_file)\n",
    "node_path = os.path.join(data_dir, node_file)\n",
    "\n",
    "results = run_simulation(node_path, edge_path, .8)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_results(base_path):\n",
    "    # Read the summary CSV files\n",
    "    log_likelihood_df = pd.read_csv(os.path.join(base_path, 'log_likelihood_summary.csv')).groupby(by=['dataset']).mean().reset_index()\n",
    "    leadership_log_likelihood_df = pd.read_csv(os.path.join(base_path, 'leadership_log_likelihood_summary.csv')).groupby(by=['dataset']).mean().reset_index()\n",
    "\n",
    "    filtered_log_like = log_likelihood_df.drop(columns=['rep'])\n",
    "    filtered_leader_like = leadership_log_likelihood_df.drop(columns=['rep'])\n",
    "    \n",
    "    log_like = subtract_columns(filtered_log_like, 3)\n",
    "    leadership_log = subtract_columns(filtered_leader_like, 4)\n",
    "\n",
    "    return log_like, leadership_log\n",
    "\n",
    "def subtract_columns(df, compared_col):\n",
    "    columns = df.columns.tolist()\n",
    "    base_column = columns[compared_col] \n",
    "    print(base_column)\n",
    "    for col in columns[1:]:\n",
    "        \n",
    "        df[col] = df[col] - df[base_column] \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_df(df, title):\n",
    "    print(f\"\\n{title}\\n\")\n",
    "    styled_df = df.style.set_table_styles(\n",
    "    ).set_properties(**{\n",
    "        'background-color': 'LightGray',\n",
    "        'color': 'black',\n",
    "        'border-color': 'black',\n",
    "        'border-style': 'solid',\n",
    "        'border-width': '1px',\n",
    "        'text-align': 'left'\n",
    "    })\n",
    "    \n",
    "\n",
    "    # print(df.to_latex(escape=True))\n",
    "    display(styled_df)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_datasets = pd.read_csv(os.path.join(os.path.join(os.getcwd(), 'results'), 'log_likelihood_summary.csv'))['dataset'].unique()\n",
    "dataset_info = pd.read_csv(os.path.join(repo_root, 'datasets', 'dataset_info.csv'))\n",
    "filtered_dataset_info = dataset_info[dataset_info['dataset_id'].isin(unique_datasets)].set_index('dataset_id')\n",
    "\n",
    "domain_order = [\"Election\", \"Sport\", \"Preferences\", \"Other\"]\n",
    "filtered_dataset_info['Domain'] = pd.Categorical(filtered_dataset_info['Domain'], categories=domain_order, ordered=True)\n",
    "\n",
    "filtered_dataset_info = filtered_dataset_info.sort_values(by=['Domain', 'K1', 'K2', 'Name'])\n",
    "\n",
    "visualize_df(filtered_dataset_info, 'Datasets Tested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_like, leadership_log = process_results(os.path.join(os.getcwd(), 'results'))\n",
    "\n",
    "def rename_df(df):\n",
    "    merged_df = df.merge(dataset_info, left_on='dataset', right_on='dataset_id').drop(columns=['dataset_id','dataset'])\n",
    "    # merged_df = merged_df.rename(columns={'Name': 'dataset_name'}).set_index('dataset_name')\n",
    "\n",
    "    domain_order = [\"Election\", \"Sport\", \"Preferences\", \"Other\"]\n",
    "    merged_df['Domain'] = pd.Categorical(merged_df['Domain'], categories=domain_order, ordered=True)\n",
    "    merged_df = merged_df.sort_values(by=['Domain', 'K1', 'K2', 'Name'])\n",
    "    merged_df = merged_df[['Domain', 'Name', 'BT','BT_leadership', 'HO_BT', 'HOL_BT', 'Spring_Rank', 'Spring_Rank_Leadership', 'Page_Rank','Page_Rank_Leadership', 'Point_Wise']]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_like = rename_df(log_like)\n",
    "visualize_df(log_like, 'log likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadership_log = rename_df(leadership_log)\n",
    "visualize_df(leadership_log, 'Leadership log likelihood')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
