{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..',))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from src.utils.file_handlers import group_dataset_files, read_dataset_files\n",
    "from src.models.BradleyTerry import compute_predicted_ratings_HO_BT\n",
    "from src.models.zermello import compute_predicted_ratings_plackett_luce\n",
    "from src.utils.metrics import measure_likelihood, measure_leadership_likelihood, measure_tau\n",
    "from src.utils.operation_helpers import run_models_synthetic, run_models, split_games\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.utils.c_operation_helpers import run_simulation_synthetic, run_simulation, run_simulation_convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-1000_M-1000_K-5_L-0\n",
      "Iterations: 52\n",
      "HO Likelihood: -4.40120956415431\n",
      "HOL Likelihood: -1.4358037845255924\n",
      "TAU: 0.422441601354638\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "for dataset in grouped:\n",
    "    print(dataset)\n",
    "    data, pi_values = read_dataset_files(grouped[dataset], data_dir, is_synthetic=True)\n",
    " \n",
    "    train, test = train_test_split(data, test_size=.8)\n",
    "    predicted, iter = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)\n",
    " \n",
    "    print(f\"Iterations: {len(iter)}\")\n",
    "    print(f\"HO Likelihood: {measure_likelihood(predicted, test)}\")\n",
    "    print(f\"HOL Likelihood: {measure_leadership_likelihood(predicted, test)}\")\n",
    "    print(f\"TAU: {measure_tau(predicted, pi_values)}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-1000_M-1000_K-5_L-0\n",
      "  model  av_error  spearman   kendall     prior   HO_Like  HOL_Like iterations\n",
      "0    HO  0.142812  0.870621  0.688136  -1.75393  -10.1199  -1.10181         17\n",
      "1   HOL   0.21433  0.634838  0.455556  -1.57324  -11.4286  -1.27797         13\n",
      "2   BIN  0.147937  0.863436  0.680601  -1.85909  -10.2599  -1.10535         13\n",
      "3  BINL  0.220474  0.630873  0.452761  -1.68693  -11.6189  -1.28272         10\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "for dataset in grouped:\n",
    "    print(dataset)\n",
    "    edge_file = grouped[dataset]['edges']\n",
    "    node_file = grouped[dataset]['nodes']\n",
    "\n",
    "    edge_path = os.path.join(data_dir, edge_file)\n",
    "    node_path = os.path.join(data_dir, node_file)\n",
    "\n",
    "    results = run_simulation_synthetic(node_path, edge_path, .8)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "522\n",
      "         model  log-likelihoods  leadership-log-likelihood\n",
      "0          BIN        -2.347709                  -0.704776\n",
      "1         BINL        -3.647801                  -0.548435\n",
      "2        HO_BT        -2.318407                  -0.748193\n",
      "3       HOL_BT        -3.404857                  -0.560377\n",
      "4  Spring_Rank        -2.079217                  -0.752441\n",
      "5    Page_Rank        -2.556301                  -1.108194\n",
      "6   Point_Wise        -2.360322                  -0.957587\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "data, pi_values = read_dataset_files(grouped['00106'], data_dir, is_synthetic=False)\n",
    "\n",
    "# train, test = train_test_split(data, test_size=.8)\n",
    "train, test = split_games(data, .8)\n",
    "\n",
    "_, info = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)        \n",
    "print(len(info))\n",
    "_, info = compute_predicted_ratings_plackett_luce(train, pi_values, verbose=True)        \n",
    "print(len(info))\n",
    "\n",
    "df = run_models(train, test, pi_values)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model  av_error    spearman     kendall     prior   HO_Like   HOL_Like  \\\n",
      "0    HO  0.421094  -0.0857143  -0.0666667  -1.54455  -6.36203  -0.775713   \n",
      "1   HOL  0.437927    0.142857   0.0666667  -1.59171  -4.06419  -0.194339   \n",
      "2   BIN  0.430317   0.0857143   0.0666667  -1.55203  -5.93088  -0.644032   \n",
      "3  BINL  0.447308   0.0845154  -0.0666667  -1.66226   -3.9374  -0.126713   \n",
      "\n",
      "  iterations  \n",
      "0          8  \n",
      "1         15  \n",
      "2          8  \n",
      "3         15  \n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "edge_file = grouped['00106']['edges']\n",
    "node_file = grouped['00106']['nodes']\n",
    "\n",
    "edge_path = os.path.join(data_dir, edge_file)\n",
    "node_path = os.path.join(data_dir, node_file)\n",
    "\n",
    "results = run_simulation(node_path, edge_path, .8)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "edge_file = grouped['00106']['edges']\n",
    "node_file = grouped['00106']['nodes']\n",
    "\n",
    "edge_path = os.path.join(data_dir, edge_file)\n",
    "node_path = os.path.join(data_dir, node_file)\n",
    "\n",
    "results = run_simulation_convergence(node_path, edge_path, 1, .8)\n",
    "print(len(results['HO']['rms_convergence_criteria']))\n",
    "print(len(results['Z']['rms_convergence_criteria']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
