{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..',))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from src.utils.file_handlers import group_dataset_files, read_dataset_files\n",
    "from src.models.BradleyTerry import compute_predicted_ratings_HO_BT\n",
    "from src.utils.metrics import measure_likelihood, measure_leadership_likelihood\n",
    "from src.utils.operation_helpers import run_models_synthetic,run_models, split_games\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 52\n",
      "HO Likelihood: -4.461310164597914\n",
      "HOL Likelihood: -1.4473425921706908\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "for dataset in grouped:\n",
    "\n",
    "    data, pi_values = read_dataset_files(grouped[dataset], data_dir, is_synthetic=True)\n",
    " \n",
    "    train, test = train_test_split(data, test_size=.8)\n",
    "    predicted, iter = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)\n",
    "    print(f\"Iterations: {len(iter)}\")\n",
    "    print(f\"HO Likelihood: {measure_likelihood(predicted, test)}\")\n",
    "    print(f\"HOL Likelihood: {measure_leadership_likelihood(predicted, test)}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-1000_M-1000_K-5_L-0\n",
      "15\n",
      "    model  log-likelihood  leadership-log-likelihood       rms       rho  \\\n",
      "0     BIN       -4.786897                  -1.617158  1.889919  0.109226   \n",
      "1    BINL       -4.779765                  -1.606945  1.894509  0.067559   \n",
      "2   HO_BT       -4.771465                  -1.605203  1.890531  0.109226   \n",
      "3  HOL_BT       -4.777030                  -1.605333  1.895519  0.067559   \n",
      "\n",
      "        tau  \n",
      "0  0.088277  \n",
      "1  0.054810  \n",
      "2  0.088277  \n",
      "3  0.054810  \n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "for dataset in grouped:\n",
    "    print(dataset)\n",
    "    data, pi_values = read_dataset_files(grouped[dataset], data_dir, is_synthetic=True)\n",
    "\n",
    "\n",
    "    train, test = train_test_split(data, test_size=.99)\n",
    "\n",
    "    _, info = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)        \n",
    "    \n",
    "    print(len(info))\n",
    "    df = run_models_synthetic(train, test, pi_values)\n",
    "    print(df)\n",
    "\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "         model  log-likelihoods  leadership-log-likelihood\n",
      "0          BIN        -0.911278                  -0.911278\n",
      "1         BINL        -0.846088                  -0.846088\n",
      "2        HO_BT        -0.834668                  -0.834668\n",
      "3       HOL_BT        -0.883993                  -0.883993\n",
      "4  Spring_Rank        -0.849152                  -0.849152\n",
      "5    Page_Rank        -0.504054                  -0.504054\n",
      "6   Point_Wise        -0.716973                  -0.716973\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "data, pi_values = read_dataset_files(grouped['00103'], data_dir, is_synthetic=False)\n",
    "\n",
    "# train, test = train_test_split(data, test_size=.995)\n",
    "train, test = split_games(data, .995)\n",
    "_, info = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)        \n",
    "print(len(info))\n",
    "df = run_models(train, test, pi_values)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
