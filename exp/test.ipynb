{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..',))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "from src.utils.file_handlers import group_dataset_files, read_dataset_files\n",
    "from src.models.BradleyTerry import compute_predicted_ratings_HO_BT\n",
    "from src.utils.metrics import measure_likelihood, measure_leadership_likelihood\n",
    "from src.utils.operation_helpers import run_models_synthetic,run_models, split_games\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 39\n",
      "HO Likelihood: -5.201703769417371\n",
      "HOL Likelihood: -1.6368784213422076\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "for dataset in grouped:\n",
    "\n",
    "    data, pi_values = read_dataset_files(grouped[dataset], data_dir, is_synthetic=True)\n",
    " \n",
    "    train, test = train_test_split(data, test_size=.8)\n",
    "    predicted, iter = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)\n",
    "    print(f\"Iterations: {len(iter)}\")\n",
    "    print(f\"HO Likelihood: {measure_likelihood(predicted, test)}\")\n",
    "    print(f\"HOL Likelihood: {measure_leadership_likelihood(predicted, test)}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-1000_M-1000_K-5_L-1\n",
      "35\n",
      "    model  log-likelihood  leadership-log-likelihood       rms       rho  \\\n",
      "0     BIN       -5.653916                  -1.866742  1.916425  0.419152   \n",
      "1    BINL       -5.546411                  -1.758931  1.848679  0.329145   \n",
      "2   HO_BT       -5.714473                  -1.945573  1.872621  0.432144   \n",
      "3  HOL_BT       -5.895562                  -1.848406  1.959358  0.249554   \n",
      "\n",
      "        tau  \n",
      "0  0.299616  \n",
      "1  0.224313  \n",
      "2  0.307552  \n",
      "3  0.170567  \n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Synthetic_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "for dataset in grouped:\n",
    "    print(dataset)\n",
    "    data, pi_values = read_dataset_files(grouped[dataset], data_dir, is_synthetic=True)\n",
    "\n",
    "\n",
    "    train, test = train_test_split(data, test_size=.8)\n",
    "\n",
    "    _, info = compute_predicted_ratings_HO_BT(train, pi_values, verbose=True)        \n",
    "    \n",
    "    print(len(info))\n",
    "    df = run_models_synthetic(train, test, pi_values)\n",
    "    print(df)\n",
    "\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  log-likelihoods  leadership-log-likelihood\n",
      "0          BIN        -1.702068                  -1.026161\n",
      "1         BINL        -1.621600                  -0.953082\n",
      "2        HO_BT        -1.556023                  -0.899944\n",
      "3       HOL_BT        -1.549362                  -0.916995\n",
      "4  Spring_Rank        -1.555677                  -0.906392\n",
      "5    Page_Rank        -2.626466                  -1.411049\n",
      "6   Point_Wise        -2.964545                  -1.408869\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(repo_root, 'datasets', 'Real_Data')\n",
    "grouped = group_dataset_files(data_dir)\n",
    "\n",
    "data, pi_values = read_dataset_files(grouped['00103'], data_dir, is_synthetic=False)\n",
    "# print(pi_values)\n",
    "train, test = train_test_split(data, test_size=.8)\n",
    "# train, test = split_games(data, .8)\n",
    "df = run_models(train, test, pi_values)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
